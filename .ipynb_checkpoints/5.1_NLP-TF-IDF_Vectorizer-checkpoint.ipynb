{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing and TF-IDF Vectorization:  Text-based Cosine Similarity\n",
    "#### In this notebook, I will process the text data to each movie, doing final cleaning of punctuation, making all words lowercase and spliting text into individual word \"tokens\" (N.B., for those who are text processing-savvy, this was done outside of Vectorizers in order to retain the '-', since curse words are represented in these reviews as s--t and f--k. The frequency with which these curse words appear in reviews may be an important text feature for parents).\n",
    "\n",
    "#### The vectorizer I will use in this notebook is TF-IDF Vectorizer. TF-IDF Vectorizer will take the frequency of words that are found in text associated with each movie and divide by the frequency with which a term appears in all of the documents put together. This technique is designed to give greater weight to terms that occur frequently in a document but not in other documents, thus controlling for words that appear frequently in all movies--- such as the word, \"movie,\" for example. It will then turn the TF-IDF statistic into the movie's \"word vector.\" These word vectors will then be run through Truncated SVD as described in Notebook 5.\n",
    "\n",
    "#### Once we get our text data into truncatedSVD format, I will use cosine similarity to determine which movies are most similar to which other movies in our data set. We will then also incorporate non-text data to see how this improves our cosine similarity-based similarity matrix (see below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Movie Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukiharuhadeishi/anaconda3/lib/python3.6/site-packages/fuzzywuzzy/fuzz.py:35: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests, re, json, copy, pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load json of movies_features_text\n",
    "with open('data/movies_features_text.json') as json_file:  \n",
    "    movies_features_text = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>slug</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>sicario-day-of-the-soldado</td>\n",
       "      <td>Families can talk about Sicario: Day of the So...</td>\n",
       "      <td>Sicario: Day of the Soldado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>damsel</td>\n",
       "      <td>Families can talk about Damsel  use of violenc...</td>\n",
       "      <td>Damsel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>distorted</td>\n",
       "      <td>Families can talk about the rapid-fire disturb...</td>\n",
       "      <td>Distorted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>the-catcher-was-a-spy</td>\n",
       "      <td>Families can talk about Berg  sexual orientati...</td>\n",
       "      <td>The Catcher Was a Spy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>boundaries</td>\n",
       "      <td>Families can talk about how Boundaries portray...</td>\n",
       "      <td>Boundaries</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                        slug  \\\n",
       "0         0  sicario-day-of-the-soldado   \n",
       "1         1                      damsel   \n",
       "2         2                   distorted   \n",
       "3         3       the-catcher-was-a-spy   \n",
       "4         4                  boundaries   \n",
       "\n",
       "                                                text  \\\n",
       "0  Families can talk about Sicario: Day of the So...   \n",
       "1  Families can talk about Damsel  use of violenc...   \n",
       "2  Families can talk about the rapid-fire disturb...   \n",
       "3  Families can talk about Berg  sexual orientati...   \n",
       "4  Families can talk about how Boundaries portray...   \n",
       "\n",
       "                         title  \n",
       "0  Sicario: Day of the Soldado  \n",
       "1                       Damsel  \n",
       "2                    Distorted  \n",
       "3        The Catcher Was a Spy  \n",
       "4                   Boundaries  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(movies_features_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_list(last_movie):\n",
    "    for movie_num in range(last_movie):\n",
    "        movie_titles = movies_features_text[movie_num]['title']\n",
    "        return movie_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Families can talk about Sicario: Day of the Soldado  violence. Which parts were gruesome, and which were exciting? How did the movie achieve these effects? What  the impact of media violence on kids?  How are drinking, smoking, and drugs depicted? Are they glamorized? Does the movie make the drug business look alluring?  What does the movie have to say about law versus justice?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_features_text[0]['text'][:380]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(stopwords.words('english'))\n",
    "# Remove punctuation from all text of each movie and remove stopwords\n",
    "def clean_text_for_movie(text):\n",
    "    '''\n",
    "    Takes in all text of a single movie, makes lowercase and removes punctuation and stopwords\n",
    "    from text. Returns words in input text as a single string, w/o English stopwords.\n",
    "    '''\n",
    "    words = re.sub(\"[^a-zA-Z\\-]\", \" \", text).lower().split()  # removes punctuation, makes lowercase\n",
    "    cleantext = [w for w in words if not w in stopwords]  # eliminates common \"stop words\"\n",
    "    return(\" \".join(cleantext))  # returns words as a string, each word separated by a space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text_test = clean_text_for_movie(movies_features_text[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'families talk sicario day soldado violence parts gruesome exciting movie achieve effects impact media violence kids drinking smoking drugs depicted glamorized movie make drug business look alluring movie say law versus justice difference two end justify means'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text_test[:259]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text = []\n",
    "def clean_text_for_movies(first_movie, num_movies_to_clean):\n",
    "    print(\"Number of movies cleaned so far:\")\n",
    "    for movie in range(num_movies_to_clean):\n",
    "        movie = (movie + first_movie)\n",
    "        if movie % 1000 == 0:\n",
    "            print(movie)\n",
    "        clean_txt = clean_text_for_movie(movies_features_text[movie]['text'])\n",
    "        movies_features_text[movie]['clean_text'] = clean_txt\n",
    "        clean_text.append(clean_txt)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of movies cleaned so far:\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n"
     ]
    }
   ],
   "source": [
    "clean_text = clean_text_for_movies(0,len(movies_features_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>slug</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>families talk sicario day soldado violence par...</td>\n",
       "      <td>0</td>\n",
       "      <td>sicario-day-of-the-soldado</td>\n",
       "      <td>Families can talk about Sicario: Day of the So...</td>\n",
       "      <td>Sicario: Day of the Soldado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>families talk damsel use violence intense freq...</td>\n",
       "      <td>1</td>\n",
       "      <td>damsel</td>\n",
       "      <td>Families can talk about Damsel  use of violenc...</td>\n",
       "      <td>Damsel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>families talk rapid-fire disturbing images dis...</td>\n",
       "      <td>2</td>\n",
       "      <td>distorted</td>\n",
       "      <td>Families can talk about the rapid-fire disturb...</td>\n",
       "      <td>Distorted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>families talk berg sexual orientation presente...</td>\n",
       "      <td>3</td>\n",
       "      <td>the-catcher-was-a-spy</td>\n",
       "      <td>Families can talk about Berg  sexual orientati...</td>\n",
       "      <td>The Catcher Was a Spy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>families talk boundaries portrays drugs drug u...</td>\n",
       "      <td>4</td>\n",
       "      <td>boundaries</td>\n",
       "      <td>Families can talk about how Boundaries portray...</td>\n",
       "      <td>Boundaries</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  movie_id  \\\n",
       "0  families talk sicario day soldado violence par...         0   \n",
       "1  families talk damsel use violence intense freq...         1   \n",
       "2  families talk rapid-fire disturbing images dis...         2   \n",
       "3  families talk berg sexual orientation presente...         3   \n",
       "4  families talk boundaries portrays drugs drug u...         4   \n",
       "\n",
       "                         slug  \\\n",
       "0  sicario-day-of-the-soldado   \n",
       "1                      damsel   \n",
       "2                   distorted   \n",
       "3       the-catcher-was-a-spy   \n",
       "4                  boundaries   \n",
       "\n",
       "                                                text  \\\n",
       "0  Families can talk about Sicario: Day of the So...   \n",
       "1  Families can talk about Damsel  use of violenc...   \n",
       "2  Families can talk about the rapid-fire disturb...   \n",
       "3  Families can talk about Berg  sexual orientati...   \n",
       "4  Families can talk about how Boundaries portray...   \n",
       "\n",
       "                         title  \n",
       "0  Sicario: Day of the Soldado  \n",
       "1                       Damsel  \n",
       "2                    Distorted  \n",
       "3        The Catcher Was a Spy  \n",
       "4                   Boundaries  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(movies_features_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Movies_features_text now has two new features, one of which contains the list of words used in movie reviews and other text associated with each of our 8625 unique movies and a second list that contains a list of bigrams of these words, to capture names of actors, separated by sentence. movies_fetures_text is now ready for vectorization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize text for NLP:  TF-IDF\n",
    "#### In this notebook, I will use a process called TF-IDF (Term Frequency Inverse Document Frequency) Vectorization on my text data to compare with my Count Vectorized predictor. TF-IDF gives the frequency of each word in the words associated with each movie (termed a \"document\") normalized by the frequency with which that word appears in all of the documents combined. In other words, words that appear frequently in text associated with all movies in general are not going to be counted as important as words that appear frequently in a small subset of documents.\n",
    "#### After TD-IDF vectorization, I will then use truncated SVD on text data alone to reduce the number of features to reduce overfitting. The components that result from truncated SVD will be examined to identify discernable patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run if you want to TF-IDF Vectorize features. Will take considerable time.\n",
    "tvec = TfidfVectorizer(analyzer = \"word\",\n",
    "                       tokenizer = None,      # tokenized in preprocessing\n",
    "                       preprocessor = None,\n",
    "                       stop_words = None,     # english stop words already removed, to retain -\n",
    "                       min_df = 2,            # to eliminate typos\n",
    "                       max_df = .9,           # to eliminate the word \"movie\"\n",
    "                       max_features = 50000) \n",
    "\n",
    "data_features_tfidf = pd.SparseDataFrame(tvec.fit_transform(clean_text),\n",
    "                                         columns=tvec.get_feature_names(),\n",
    "                                         default_fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_features_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa',\n",
       " 'aaa',\n",
       " 'aaah',\n",
       " 'aardman',\n",
       " 'aaron',\n",
       " 'aasif',\n",
       " 'aback',\n",
       " 'abacus',\n",
       " 'abandon',\n",
       " 'abandoned',\n",
       " 'abandoning',\n",
       " 'abandonment',\n",
       " 'abandons',\n",
       " 'abashed',\n",
       " 'abba',\n",
       " 'abbate',\n",
       " 'abbess',\n",
       " 'abbey',\n",
       " 'abbi',\n",
       " 'abbie',\n",
       " 'abbot',\n",
       " 'abbott',\n",
       " 'abbreviated',\n",
       " 'abby',\n",
       " 'abc',\n",
       " 'abdalla',\n",
       " 'abdellatif',\n",
       " 'abdi',\n",
       " 'abdicate',\n",
       " 'abdication',\n",
       " 'abdomen',\n",
       " 'abduct',\n",
       " 'abducted',\n",
       " 'abducting',\n",
       " 'abduction',\n",
       " 'abductions',\n",
       " 'abductors',\n",
       " 'abducts',\n",
       " 'abdul',\n",
       " 'abe',\n",
       " 'abel',\n",
       " 'abell',\n",
       " 'abercrombie',\n",
       " 'aberrant',\n",
       " 'abetted',\n",
       " 'abhor',\n",
       " 'abhorrent',\n",
       " 'abhorrently',\n",
       " 'abhors',\n",
       " 'abi',\n",
       " 'abide',\n",
       " 'abiding',\n",
       " 'abigail',\n",
       " 'abilities',\n",
       " 'ability',\n",
       " 'abin',\n",
       " 'abject',\n",
       " 'ablaze',\n",
       " 'able',\n",
       " 'abled',\n",
       " 'ably',\n",
       " 'abnegation',\n",
       " 'abner',\n",
       " 'abnormal',\n",
       " 'abnormalities',\n",
       " 'abnormally',\n",
       " 'abo',\n",
       " 'aboard',\n",
       " 'abode',\n",
       " 'abolish',\n",
       " 'abolished',\n",
       " 'abolishing',\n",
       " 'abolition',\n",
       " 'abolitionist',\n",
       " 'abolitionists',\n",
       " 'abominable',\n",
       " 'abominably',\n",
       " 'abomination',\n",
       " 'abominations',\n",
       " 'aboriginal',\n",
       " 'aborigine',\n",
       " 'aborigines',\n",
       " 'abort',\n",
       " 'aborted',\n",
       " 'abortion',\n",
       " 'abortions',\n",
       " 'aboud',\n",
       " 'abound',\n",
       " 'abounding',\n",
       " 'abounds',\n",
       " 'about',\n",
       " 'aboutthe',\n",
       " 'above',\n",
       " 'abraham',\n",
       " 'abrahams',\n",
       " 'abrahamson',\n",
       " 'abramoff',\n",
       " 'abrams',\n",
       " 'abrasions',\n",
       " 'abrasive',\n",
       " 'abrasiveness',\n",
       " 'abreu',\n",
       " 'abroad',\n",
       " 'abrupt',\n",
       " 'abruptly',\n",
       " 'abruptness',\n",
       " 'abs',\n",
       " 'absence',\n",
       " 'absences',\n",
       " 'absent',\n",
       " 'absentee',\n",
       " 'absinthe',\n",
       " 'absolut',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absolutes',\n",
       " 'absolve',\n",
       " 'absorb',\n",
       " 'absorbed',\n",
       " 'absorbing',\n",
       " 'absorbingly',\n",
       " 'absorbs',\n",
       " 'absorption',\n",
       " 'abstain',\n",
       " 'abstaining',\n",
       " 'abstains',\n",
       " 'abstinence',\n",
       " 'abstinent',\n",
       " 'abstract',\n",
       " 'abstracted',\n",
       " 'abstractly',\n",
       " 'absurd',\n",
       " 'absurdist',\n",
       " 'absurdities',\n",
       " 'absurdity',\n",
       " 'absurdly',\n",
       " 'abu',\n",
       " 'abuelita',\n",
       " 'abundance',\n",
       " 'abundant',\n",
       " 'abundantly',\n",
       " 'abuse',\n",
       " 'abused',\n",
       " 'abuser',\n",
       " 'abusers',\n",
       " 'abuses',\n",
       " 'abusing',\n",
       " 'abusive',\n",
       " 'abusively',\n",
       " 'abusiveness',\n",
       " 'abuzz',\n",
       " 'abysmal',\n",
       " 'abyss',\n",
       " 'ac',\n",
       " 'academia',\n",
       " 'academic',\n",
       " 'academically',\n",
       " 'academics',\n",
       " 'academy',\n",
       " 'accelerate',\n",
       " 'accelerated',\n",
       " 'accelerates',\n",
       " 'accelerating',\n",
       " 'accent',\n",
       " 'accented',\n",
       " 'accents',\n",
       " 'accentuate',\n",
       " 'accentuated',\n",
       " 'accentuates',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'acceptably',\n",
       " 'acceptance',\n",
       " 'acceptances',\n",
       " 'accepted',\n",
       " 'accepting',\n",
       " 'accepts',\n",
       " 'access',\n",
       " 'accessed',\n",
       " 'accessibility',\n",
       " 'accessible',\n",
       " 'accessing',\n",
       " 'accessories',\n",
       " 'accessorizing',\n",
       " 'accessory',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'accidentally',\n",
       " 'accidently',\n",
       " 'accidents',\n",
       " 'acclaim',\n",
       " 'acclaimed',\n",
       " 'acclimate',\n",
       " 'acclimates',\n",
       " 'accolade',\n",
       " 'accolades',\n",
       " 'accommodate',\n",
       " 'accommodating',\n",
       " 'accommodations',\n",
       " 'accompanied',\n",
       " 'accompanies',\n",
       " 'accompaniment',\n",
       " 'accompaniments',\n",
       " 'accompany',\n",
       " 'accompanying',\n",
       " 'accomplice',\n",
       " 'accomplices',\n",
       " 'accomplish',\n",
       " 'accomplished',\n",
       " 'accomplishes',\n",
       " 'accomplishing',\n",
       " 'accomplishment',\n",
       " 'accomplishments',\n",
       " 'accord',\n",
       " 'accordance',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'accosted',\n",
       " 'accosts',\n",
       " 'account',\n",
       " 'accountability',\n",
       " 'accountable',\n",
       " 'accountant',\n",
       " 'accountants',\n",
       " 'accounted',\n",
       " 'accounting',\n",
       " 'accounts',\n",
       " 'accouterments',\n",
       " 'accredited',\n",
       " 'accruing',\n",
       " 'accumulate',\n",
       " 'accumulating',\n",
       " 'accumulation',\n",
       " 'accuracy',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'accusation',\n",
       " 'accusations',\n",
       " 'accuse',\n",
       " 'accused',\n",
       " 'accuser',\n",
       " 'accusers',\n",
       " 'accuses',\n",
       " 'accusing',\n",
       " 'accustomed',\n",
       " 'ace',\n",
       " 'acer',\n",
       " 'acerbic',\n",
       " 'aces',\n",
       " 'acevedo',\n",
       " 'ache',\n",
       " 'aches',\n",
       " 'achieve',\n",
       " 'achieved',\n",
       " 'achievement',\n",
       " 'achievements',\n",
       " 'achiever',\n",
       " 'achievers',\n",
       " 'achieves',\n",
       " 'achieving',\n",
       " 'achilles',\n",
       " 'aching',\n",
       " 'achingly',\n",
       " 'achy',\n",
       " 'acid',\n",
       " 'acidic',\n",
       " 'acker',\n",
       " 'ackerman',\n",
       " 'ackles',\n",
       " 'acknowledge',\n",
       " 'acknowledged',\n",
       " 'acknowledgement',\n",
       " 'acknowledges',\n",
       " 'acknowledging',\n",
       " 'acknowledgment',\n",
       " 'ackroyd',\n",
       " 'aclu',\n",
       " 'acme',\n",
       " 'acne',\n",
       " 'acolyte',\n",
       " 'acolytes',\n",
       " 'acorn',\n",
       " 'acorns',\n",
       " 'acosta',\n",
       " 'acquaint',\n",
       " 'acquaintance',\n",
       " 'acquaintances',\n",
       " 'acquainted',\n",
       " 'acquaints',\n",
       " 'acquiesce',\n",
       " 'acquiescence',\n",
       " 'acquiesces',\n",
       " 'acquire',\n",
       " 'acquired',\n",
       " 'acquires',\n",
       " 'acquiring',\n",
       " 'acquisition',\n",
       " 'acquisitiveness',\n",
       " 'acquit',\n",
       " 'acquits',\n",
       " 'acquittal',\n",
       " 'acquitted',\n",
       " 'acre',\n",
       " 'acreage',\n",
       " 'acres',\n",
       " 'acrimonious',\n",
       " 'acrimony',\n",
       " 'acrobat',\n",
       " 'acrobatic',\n",
       " 'acrobatics',\n",
       " 'acrobats',\n",
       " 'acronym',\n",
       " 'across',\n",
       " 'act',\n",
       " 'acted',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actioner',\n",
       " 'actions',\n",
       " 'activate',\n",
       " 'activated',\n",
       " 'activates',\n",
       " 'activating',\n",
       " 'active',\n",
       " 'actively',\n",
       " 'activism',\n",
       " 'activist',\n",
       " 'activists',\n",
       " 'activities',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'actorly',\n",
       " 'actors',\n",
       " 'actress',\n",
       " 'actresses',\n",
       " 'acts',\n",
       " 'actual',\n",
       " 'actuality',\n",
       " 'actualization',\n",
       " 'actualized',\n",
       " 'actually',\n",
       " 'acuity',\n",
       " 'acumen',\n",
       " 'acupuncture',\n",
       " 'acura',\n",
       " 'acute',\n",
       " 'acutely',\n",
       " 'ad',\n",
       " 'ada',\n",
       " 'adage',\n",
       " 'adages',\n",
       " 'adagio',\n",
       " 'adair',\n",
       " 'adam',\n",
       " 'adamant',\n",
       " 'adamantly',\n",
       " 'adams',\n",
       " 'adamson',\n",
       " 'adapt',\n",
       " 'adaptable',\n",
       " 'adaptation',\n",
       " 'adaptations',\n",
       " 'adapted',\n",
       " 'adapter',\n",
       " 'adapting',\n",
       " 'adaption',\n",
       " 'adapts',\n",
       " 'add',\n",
       " 'addai',\n",
       " 'addams',\n",
       " 'addamses',\n",
       " 'addario',\n",
       " 'added',\n",
       " 'addendum',\n",
       " 'adderall',\n",
       " 'addict',\n",
       " 'addicted',\n",
       " 'addicting',\n",
       " 'addiction',\n",
       " 'addictions',\n",
       " 'addictive',\n",
       " 'addicts',\n",
       " 'addie',\n",
       " 'adding',\n",
       " 'addison',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'additionally',\n",
       " 'additions',\n",
       " 'addled',\n",
       " 'address',\n",
       " 'addressed',\n",
       " 'addresses',\n",
       " 'addressing',\n",
       " 'adds',\n",
       " 'addy',\n",
       " 'ade',\n",
       " 'adelaide',\n",
       " 'adele',\n",
       " 'adelie',\n",
       " 'adept',\n",
       " 'adeptly',\n",
       " 'adequate',\n",
       " 'adequately',\n",
       " 'adewale',\n",
       " 'adhd',\n",
       " 'adhere',\n",
       " 'adherence',\n",
       " 'adherents',\n",
       " 'adheres',\n",
       " 'adhering',\n",
       " 'adidas',\n",
       " 'adios',\n",
       " 'adira',\n",
       " 'adjacent',\n",
       " 'adjective',\n",
       " 'adjectives',\n",
       " 'adjoining',\n",
       " 'adjust',\n",
       " 'adjusted',\n",
       " 'adjuster',\n",
       " 'adjusting',\n",
       " 'adjustment',\n",
       " 'adjustments',\n",
       " 'adjusts',\n",
       " 'adkins',\n",
       " 'adler',\n",
       " 'adlon',\n",
       " 'administer',\n",
       " 'administered',\n",
       " 'administering',\n",
       " 'administers',\n",
       " 'administration',\n",
       " 'administrations',\n",
       " 'administrative',\n",
       " 'administrator',\n",
       " 'administrators',\n",
       " 'admirable',\n",
       " 'admirably',\n",
       " 'admiral',\n",
       " 'admiration',\n",
       " 'admire',\n",
       " 'admired',\n",
       " 'admirer',\n",
       " 'admirers',\n",
       " 'admires',\n",
       " 'admiring',\n",
       " 'admiringly',\n",
       " 'admission',\n",
       " 'admissions',\n",
       " 'admit',\n",
       " 'admits',\n",
       " 'admitted',\n",
       " 'admittedly',\n",
       " 'admitting',\n",
       " 'admonished',\n",
       " 'admonishes',\n",
       " 'admonishing',\n",
       " 'admonishments',\n",
       " 'admonition',\n",
       " 'admonitions',\n",
       " 'ado',\n",
       " 'adolescence',\n",
       " 'adolescent',\n",
       " 'adolescents',\n",
       " 'adolf',\n",
       " 'adolphe',\n",
       " 'adopt',\n",
       " 'adoptable',\n",
       " 'adopted',\n",
       " 'adopting',\n",
       " 'adoption',\n",
       " 'adoptive',\n",
       " 'adopts',\n",
       " 'adorability',\n",
       " 'adorable',\n",
       " 'adorableness',\n",
       " 'adorably',\n",
       " 'adoration',\n",
       " 'adore',\n",
       " 'adored',\n",
       " 'adores',\n",
       " 'adoring',\n",
       " 'adorkable',\n",
       " 'adorn',\n",
       " 'adorned',\n",
       " 'adornments',\n",
       " 'adrenalin',\n",
       " 'adrenaline',\n",
       " 'adrian',\n",
       " 'adriana',\n",
       " 'adrianne',\n",
       " 'adrien',\n",
       " 'adrienne',\n",
       " 'adrift',\n",
       " 'adroit',\n",
       " 'ads',\n",
       " 'aduba',\n",
       " 'adulation',\n",
       " 'adult',\n",
       " 'adulterer',\n",
       " 'adulterers',\n",
       " 'adulterous',\n",
       " 'adultery',\n",
       " 'adulthood',\n",
       " 'adultrous',\n",
       " 'adults',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advancement',\n",
       " 'advancements',\n",
       " 'advances',\n",
       " 'advancing',\n",
       " 'advantage',\n",
       " 'advantageous',\n",
       " 'advantages',\n",
       " 'advent',\n",
       " 'adventist',\n",
       " 'adventure',\n",
       " 'adventureland',\n",
       " 'adventurer',\n",
       " 'adventurers',\n",
       " 'adventures',\n",
       " 'adventuresome',\n",
       " 'adventuring',\n",
       " 'adventurous',\n",
       " 'adventurousness',\n",
       " 'adversarial',\n",
       " 'adversaries',\n",
       " 'adversary',\n",
       " 'adverse',\n",
       " 'adversely',\n",
       " 'adversities',\n",
       " 'adversity',\n",
       " 'advertise',\n",
       " 'advertised',\n",
       " 'advertisement',\n",
       " 'advertisements',\n",
       " 'advertiser',\n",
       " 'advertisers',\n",
       " 'advertises',\n",
       " 'advertising',\n",
       " 'advice',\n",
       " 'advil',\n",
       " 'advisable',\n",
       " 'advise',\n",
       " 'advised',\n",
       " 'adviser',\n",
       " 'advisers',\n",
       " 'advises',\n",
       " 'advising',\n",
       " 'advisor',\n",
       " 'advisors',\n",
       " 'advisory',\n",
       " 'advocacy',\n",
       " 'advocate',\n",
       " 'advocated',\n",
       " 'advocates',\n",
       " 'advocating',\n",
       " 'aeon',\n",
       " 'aerial',\n",
       " 'aerobics',\n",
       " 'aeronautical',\n",
       " 'aeropostale',\n",
       " 'aerosmith',\n",
       " 'aerosol',\n",
       " 'aerospace',\n",
       " 'aesop',\n",
       " 'aesthetic',\n",
       " 'aesthetically',\n",
       " 'aesthetics',\n",
       " 'afar',\n",
       " 'affable',\n",
       " 'affair',\n",
       " 'affairs',\n",
       " 'affect',\n",
       " 'affectations',\n",
       " 'affected',\n",
       " 'affecting',\n",
       " 'affectingly',\n",
       " 'affection',\n",
       " 'affectionate',\n",
       " 'affectionately',\n",
       " 'affections',\n",
       " 'affectless',\n",
       " 'affects',\n",
       " 'affiliated',\n",
       " 'affiliates',\n",
       " 'affiliation',\n",
       " 'affiliations',\n",
       " 'affinity',\n",
       " 'affirm',\n",
       " 'affirmation',\n",
       " 'affirmations',\n",
       " 'affirmative',\n",
       " 'affirmatively',\n",
       " 'affirmed',\n",
       " 'affirming',\n",
       " 'affirms',\n",
       " 'affix',\n",
       " 'affleck',\n",
       " 'afflict',\n",
       " 'afflicted',\n",
       " 'affliction',\n",
       " 'afflicts',\n",
       " 'affluence',\n",
       " 'affluent',\n",
       " 'affluenza',\n",
       " 'afford',\n",
       " 'affordable',\n",
       " 'afforded',\n",
       " 'affording',\n",
       " 'affords',\n",
       " 'affront',\n",
       " 'afghan',\n",
       " 'afghani',\n",
       " 'afghanistan',\n",
       " 'afghans',\n",
       " 'aficionado',\n",
       " 'aficionados',\n",
       " 'afire',\n",
       " 'aflame',\n",
       " 'afloat',\n",
       " 'afoot',\n",
       " 'aforementioned',\n",
       " 'afoul',\n",
       " 'afraid',\n",
       " 'afresh',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'africans',\n",
       " 'afrikaans',\n",
       " 'afrikaner',\n",
       " 'afro',\n",
       " 'after',\n",
       " 'aftereffects',\n",
       " 'afterglow',\n",
       " 'afterlife',\n",
       " 'aftermath',\n",
       " 'aftermaths',\n",
       " 'afternoon',\n",
       " 'afternoons',\n",
       " 'afters',\n",
       " 'afterschool',\n",
       " 'aftershocks',\n",
       " 'aftertaste',\n",
       " 'afterthought',\n",
       " 'afterthoughts',\n",
       " 'afterward',\n",
       " 'afterwards',\n",
       " 'ag',\n",
       " 'again',\n",
       " 'against',\n",
       " 'agamemnon',\n",
       " 'agate',\n",
       " 'agatha',\n",
       " 'agathe',\n",
       " 'agbaje',\n",
       " 'age',\n",
       " 'aged',\n",
       " 'agee',\n",
       " 'ageism',\n",
       " 'ageless',\n",
       " 'agen',\n",
       " 'agencies',\n",
       " 'agency',\n",
       " 'agenda',\n",
       " 'agendas',\n",
       " 'agent',\n",
       " 'agents',\n",
       " 'agers',\n",
       " 'ages',\n",
       " 'agey',\n",
       " 'aggie',\n",
       " 'aggrandizement',\n",
       " 'aggrandizing',\n",
       " 'aggravate',\n",
       " 'aggravated',\n",
       " 'aggravating',\n",
       " 'aggravatingly',\n",
       " 'aggression',\n",
       " 'aggressions',\n",
       " 'aggressive',\n",
       " 'aggressively',\n",
       " 'aggressiveness',\n",
       " 'aggressor',\n",
       " 'aggressors',\n",
       " 'aggrieved',\n",
       " 'aghast',\n",
       " 'aghdashloo',\n",
       " 'agile',\n",
       " 'agility',\n",
       " 'aging',\n",
       " 'agitate',\n",
       " 'agitated',\n",
       " 'agitating',\n",
       " 'agitation',\n",
       " 'agitator',\n",
       " 'aglow',\n",
       " 'agnes',\n",
       " 'ago',\n",
       " 'agonies',\n",
       " 'agonized',\n",
       " 'agonizes',\n",
       " 'agonizing',\n",
       " 'agonizingly',\n",
       " 'agony',\n",
       " 'agoraphobia',\n",
       " 'agoraphobic',\n",
       " 'agosto',\n",
       " 'agrabah',\n",
       " 'agrarian',\n",
       " 'agree',\n",
       " 'agreeable',\n",
       " 'agreeably',\n",
       " 'agreed',\n",
       " 'agreeing',\n",
       " 'agreement',\n",
       " 'agreements',\n",
       " 'agrees',\n",
       " 'agribusiness',\n",
       " 'agricultural',\n",
       " 'agriculture',\n",
       " 'agron',\n",
       " 'aground',\n",
       " 'aguilera',\n",
       " 'aguirre',\n",
       " 'agutter',\n",
       " 'ah',\n",
       " 'aha',\n",
       " 'ahead',\n",
       " 'ahem',\n",
       " 'ahh',\n",
       " 'ahmad',\n",
       " 'ahmed',\n",
       " 'ahna',\n",
       " 'ahold',\n",
       " 'ahoy',\n",
       " 'ahrens',\n",
       " 'ai',\n",
       " 'aid',\n",
       " 'aidan',\n",
       " 'aide',\n",
       " 'aided',\n",
       " 'aiden',\n",
       " 'aides',\n",
       " 'aiding',\n",
       " 'aids',\n",
       " 'aidy',\n",
       " 'aiello',\n",
       " 'aiken',\n",
       " 'aileen',\n",
       " 'ailing',\n",
       " 'ailment',\n",
       " 'ailments',\n",
       " 'ails',\n",
       " 'aim',\n",
       " 'aime',\n",
       " 'aimed',\n",
       " 'aimee',\n",
       " 'aimes',\n",
       " 'aiming',\n",
       " 'aimless',\n",
       " 'aimlessly',\n",
       " 'aimlessness',\n",
       " 'aims',\n",
       " 'ainscough',\n",
       " 'ainsworth',\n",
       " 'air',\n",
       " 'airbags',\n",
       " 'airbender',\n",
       " 'airborne',\n",
       " 'airbus',\n",
       " 'aircraft',\n",
       " 'aired',\n",
       " 'aires',\n",
       " 'airhead',\n",
       " 'airheaded',\n",
       " 'airheadish',\n",
       " 'airheads',\n",
       " 'airing',\n",
       " 'airless',\n",
       " 'airline',\n",
       " 'airliner',\n",
       " 'airlines',\n",
       " 'airmen',\n",
       " 'airplane',\n",
       " 'airplanes',\n",
       " 'airport',\n",
       " 'airports',\n",
       " 'airs',\n",
       " 'airship',\n",
       " 'airships',\n",
       " 'airtight',\n",
       " 'airwaves',\n",
       " 'airways',\n",
       " 'airy',\n",
       " 'aisha',\n",
       " 'aishwarya',\n",
       " 'aisle',\n",
       " 'aisles',\n",
       " 'aisling',\n",
       " 'aislinn',\n",
       " 'aj',\n",
       " 'aja',\n",
       " 'ajar',\n",
       " 'ajax',\n",
       " 'ak',\n",
       " 'aka',\n",
       " 'akeelah',\n",
       " 'akerman',\n",
       " 'akhtar',\n",
       " 'aki',\n",
       " 'akin',\n",
       " 'akinnuoye',\n",
       " 'akira',\n",
       " 'akiva',\n",
       " 'akka',\n",
       " 'akron',\n",
       " 'aksel',\n",
       " 'al',\n",
       " 'ala',\n",
       " 'alabama',\n",
       " 'alabaster',\n",
       " 'aladdin',\n",
       " 'alain',\n",
       " 'alakazam',\n",
       " 'alamo',\n",
       " 'alan',\n",
       " 'alana',\n",
       " 'alanis',\n",
       " 'alanna',\n",
       " 'alarm',\n",
       " 'alarmed',\n",
       " 'alarming',\n",
       " 'alarmingly',\n",
       " 'alarmist',\n",
       " 'alarms',\n",
       " 'alas',\n",
       " 'alaska',\n",
       " 'alaskan',\n",
       " 'alaskey',\n",
       " 'alastair',\n",
       " 'alazraqui',\n",
       " 'alba',\n",
       " 'albania',\n",
       " 'albanian',\n",
       " 'albatross',\n",
       " 'albeit',\n",
       " 'albert',\n",
       " 'alberto',\n",
       " 'albertson',\n",
       " 'albino',\n",
       " 'albion',\n",
       " 'albright',\n",
       " 'albrizzi',\n",
       " 'album',\n",
       " 'albums',\n",
       " 'albuquerque',\n",
       " 'alcatraz',\n",
       " 'alchemist',\n",
       " 'alchemy',\n",
       " 'alcohol',\n",
       " 'alcoholic',\n",
       " 'alcoholics',\n",
       " 'alcoholism',\n",
       " 'alcott',\n",
       " 'alda',\n",
       " 'alden',\n",
       " 'alderman',\n",
       " 'aldo',\n",
       " 'aldous',\n",
       " 'aldrich',\n",
       " 'aldrin',\n",
       " 'ale',\n",
       " 'alec',\n",
       " 'alecia',\n",
       " 'aleck',\n",
       " 'alecky',\n",
       " 'aleisha',\n",
       " 'alejandra',\n",
       " 'alejandro',\n",
       " 'aleks',\n",
       " 'alert',\n",
       " 'alerted',\n",
       " 'alerting',\n",
       " 'alerts',\n",
       " 'alessandro',\n",
       " 'alex',\n",
       " 'alexa',\n",
       " 'alexander',\n",
       " 'alexandra',\n",
       " 'alexandre',\n",
       " 'alexandria',\n",
       " 'alexei',\n",
       " 'alexi',\n",
       " 'alexia',\n",
       " 'alexis',\n",
       " 'alf',\n",
       " 'alfa',\n",
       " 'alfalfa',\n",
       " 'alfie',\n",
       " 'alfonso',\n",
       " 'alfre',\n",
       " 'alfred',\n",
       " 'alfredson',\n",
       " 'algae',\n",
       " 'algebra',\n",
       " 'alger',\n",
       " 'algerian',\n",
       " 'algonquin',\n",
       " 'ali',\n",
       " 'alia',\n",
       " 'alias',\n",
       " 'alibi',\n",
       " 'alibis',\n",
       " 'alice',\n",
       " 'alicia',\n",
       " 'alien',\n",
       " 'alienate',\n",
       " 'alienated',\n",
       " 'alienates',\n",
       " 'alienating',\n",
       " 'alienation',\n",
       " 'aliens',\n",
       " 'alighting',\n",
       " 'align',\n",
       " 'aligned',\n",
       " 'aligns',\n",
       " 'alike',\n",
       " 'alimony',\n",
       " 'alina',\n",
       " 'aline',\n",
       " 'alisa',\n",
       " 'alise',\n",
       " 'alison',\n",
       " 'alistair',\n",
       " 'alitalia',\n",
       " 'alive',\n",
       " 'alka',\n",
       " 'all',\n",
       " 'allam',\n",
       " 'allan',\n",
       " 'allegations',\n",
       " 'alleged',\n",
       " 'allegedly',\n",
       " 'alleges',\n",
       " 'allegiance',\n",
       " 'allegiances',\n",
       " 'allegiant',\n",
       " 'allegorical',\n",
       " 'allegory',\n",
       " 'allen',\n",
       " 'allende',\n",
       " 'allergic',\n",
       " 'allergies',\n",
       " 'allergy',\n",
       " 'allesandro',\n",
       " 'alleviate',\n",
       " 'alleviated',\n",
       " 'alley',\n",
       " 'alleys',\n",
       " 'alliance',\n",
       " 'alliances',\n",
       " 'allie',\n",
       " 'allied',\n",
       " 'allies',\n",
       " 'alligator',\n",
       " 'alligators',\n",
       " 'allin',\n",
       " 'allison',\n",
       " 'allocation',\n",
       " 'allotted',\n",
       " 'allow',\n",
       " 'allowable',\n",
       " 'allowance',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'allred',\n",
       " 'allsburg',\n",
       " 'allstate',\n",
       " 'allude',\n",
       " 'alluded',\n",
       " 'alludes',\n",
       " 'alluding',\n",
       " 'allure',\n",
       " 'alluring',\n",
       " 'alluringly',\n",
       " 'allusion',\n",
       " 'allusions',\n",
       " 'allusive',\n",
       " 'allwine',\n",
       " 'ally',\n",
       " 'allyson',\n",
       " 'alma',\n",
       " 'almanac',\n",
       " 'almeida',\n",
       " 'almighty',\n",
       " 'almod',\n",
       " ...]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = tvec.get_feature_names()\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Truncated SVD\n",
    "#### To generate vectors that encapsulate the most variance in our text data in the fewest number of components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidfvec_truncated is fit_transformed w/1000 components\n",
    "tfidfvec_truncated = svd.fit_transform(data_features_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8625, 1000)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfvec_truncated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns are svd components, 0 - 999, for tf-idf vectorized words; index is words\n",
    "components_tfidfvec = pd.DataFrame(svd.components_.T, index=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42188, 1000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "components_tfidfvec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore components to identify meanings of components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "characters    0.145347\n",
       "one           0.140572\n",
       "sex           0.115348\n",
       "character     0.111659\n",
       "film          0.106805\n",
       "violence      0.106770\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_importance_component_1 = components_tfidfvec[0].sort_values(ascending=False)\n",
    "word_importance_component_1[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prejudge            0.000025\n",
       "beliebers           0.000025\n",
       "persson             0.000023\n",
       "sundberg            0.000023\n",
       "rebranding          0.000023\n",
       "anthropomorphize    0.000020\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_importance_component_1[-7:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_importances = {}\n",
    "word_importances.append(word_importance_component_1[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "christmas    0.303203\n",
       "kids         0.204020\n",
       "santa        0.142073\n",
       "holiday      0.137228\n",
       "dog          0.133801\n",
       "family       0.129417\n",
       "Name: 1, dtype: float64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_importance_component_2 = components_tfidfvec[1].sort_values(ascending=False)\n",
    "word_importance_component_2[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nudity     -0.098234\n",
       "violence   -0.102057\n",
       "women      -0.103081\n",
       "shown      -0.109350\n",
       "drug       -0.118820\n",
       "sexual     -0.125117\n",
       "Name: 1, dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_importance_component_2[-7:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "school       0.203101\n",
       "sex          0.173508\n",
       "teen         0.153460\n",
       "girls        0.117679\n",
       "christmas    0.116954\n",
       "teens        0.115779\n",
       "Name: 2, dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_importance_component_3 = components_tfidfvec[2].sort_values(ascending=False)\n",
    "word_importance_component_3[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evil     -0.092100\n",
       "horror   -0.095386\n",
       "scary    -0.100603\n",
       "blood    -0.114092\n",
       "war      -0.148512\n",
       "action   -0.171642\n",
       "Name: 2, dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_importance_component_3[-7:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dog        0.436106\n",
       "dogs       0.203989\n",
       "animals    0.180841\n",
       "animal     0.124016\n",
       "family     0.122604\n",
       "man        0.099306\n",
       "Name: 5, dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_importance_component_6 = components_tfidfvec[5].sort_values(ascending=False)\n",
    "word_importance_component_6[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "war         -0.121366\n",
       "santa       -0.124257\n",
       "teen        -0.175223\n",
       "girls       -0.177246\n",
       "high        -0.185521\n",
       "christmas   -0.207730\n",
       "Name: 5, dtype: float64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_importance_component_6[-7:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dog       0.436691\n",
       "war       0.210951\n",
       "dogs      0.194946\n",
       "team      0.167513\n",
       "school    0.156317\n",
       "sports    0.142064\n",
       "Name: 7, dtype: float64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_importance_component_8 = components_tfidfvec[7].sort_values(ascending=False)\n",
    "word_importance_component_8[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "magic     -0.071185\n",
       "fantasy   -0.077160\n",
       "horror    -0.083386\n",
       "fairy     -0.092961\n",
       "scary     -0.110499\n",
       "love      -0.114002\n",
       "Name: 7, dtype: float64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_importance_component_8[-7:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_importance_df = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_importance_df = comp_1:word_importance_component_1[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svd_explained_variance = svd.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_sum_explained_variance = []\n",
    "def cum_sum_explained_var(vect, total_comp):\n",
    "    cum_sum_explained_variance = []\n",
    "    if total_comp > len(vect.explained_variance_):\n",
    "        print(\"That's too many components. Max_components is 1000\\.\\n\")\n",
    "        total_comp = int(input(\"Enter new total_components:\"))\n",
    "    else:\n",
    "        pass\n",
    "    cum_sum_var = 0\n",
    "    for i in range(total_comp):\n",
    "        cum_sum_var += vect.explained_variance_[i]\n",
    "        cum_sum_explained_variance.append({i, cum_sum_var})\n",
    "    return cum_sum_explained_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell to get cumulative list of explained variances. Only 40% of variance explained by\n",
    "# text features...\n",
    "\n",
    "# cum_sum_explained_var(svd, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_features_tfidf.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pd.DataFrame(index=feature_names, columns=components_tfidf)\n",
    "## tfidf_features['feature names'] = vocab\n",
    "## #pd.DataFrame(features_components_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity:  TFIDF_truncSVD1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calcualte as matrix of all movies to all movies of  countvec_truncated\n",
    "sim_matrix_tfidfvec_truncSVD1000 = cosine_similarity(tfidfvec_truncated, tfidfvec_truncated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix_tfidfvec_truncSVD1000 = pd.DataFrame(sim_matrix_tfidfvec_truncSVD1000,\n",
    "                                                       columns=df['title'], index=df['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(similarity_matrix_tfidfvec_truncSVD1000,\n",
    "            open(\"similarity_matrix_tfidfvec_truncSVD1000.pkl\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>title</th>\n",
       "      <th>Sicario: Day of the Soldado</th>\n",
       "      <th>Damsel</th>\n",
       "      <th>Distorted</th>\n",
       "      <th>The Catcher Was a Spy</th>\n",
       "      <th>Boundaries</th>\n",
       "      <th>Izzy Gets the F*ck Across Town</th>\n",
       "      <th>Jurassic World: Fallen Kingdom</th>\n",
       "      <th>Brothers of the Wind</th>\n",
       "      <th>Unsane</th>\n",
       "      <th>Flower</th>\n",
       "      <th>...</th>\n",
       "      <th>Live and Let Die</th>\n",
       "      <th>Tintin: The Lake of Sharks</th>\n",
       "      <th>Tales of Beatrix Potter</th>\n",
       "      <th>Tintin: The Prisoners of the Sun</th>\n",
       "      <th>Gentle Giant</th>\n",
       "      <th>Tintin: The Calculus Affair</th>\n",
       "      <th>Visit to a Small Planet</th>\n",
       "      <th>Zoo Baby</th>\n",
       "      <th>Driftwood</th>\n",
       "      <th>Sherlock Jr.</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sicario: Day of the Soldado</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.191863</td>\n",
       "      <td>0.121058</td>\n",
       "      <td>0.105026</td>\n",
       "      <td>0.190047</td>\n",
       "      <td>0.118741</td>\n",
       "      <td>0.133465</td>\n",
       "      <td>0.084356</td>\n",
       "      <td>0.119499</td>\n",
       "      <td>0.148502</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160482</td>\n",
       "      <td>0.065431</td>\n",
       "      <td>0.080594</td>\n",
       "      <td>0.049716</td>\n",
       "      <td>0.082526</td>\n",
       "      <td>0.055607</td>\n",
       "      <td>0.120428</td>\n",
       "      <td>0.034805</td>\n",
       "      <td>0.063027</td>\n",
       "      <td>0.073078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Damsel</th>\n",
       "      <td>0.191863</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.155643</td>\n",
       "      <td>0.129720</td>\n",
       "      <td>0.253115</td>\n",
       "      <td>0.173843</td>\n",
       "      <td>0.107899</td>\n",
       "      <td>0.098123</td>\n",
       "      <td>0.173747</td>\n",
       "      <td>0.122491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093100</td>\n",
       "      <td>0.051277</td>\n",
       "      <td>0.057892</td>\n",
       "      <td>0.037933</td>\n",
       "      <td>0.078350</td>\n",
       "      <td>0.039502</td>\n",
       "      <td>0.109071</td>\n",
       "      <td>0.041265</td>\n",
       "      <td>0.084943</td>\n",
       "      <td>0.072520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Distorted</th>\n",
       "      <td>0.121058</td>\n",
       "      <td>0.155643</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.134186</td>\n",
       "      <td>0.085488</td>\n",
       "      <td>0.111801</td>\n",
       "      <td>0.079050</td>\n",
       "      <td>0.142336</td>\n",
       "      <td>0.330883</td>\n",
       "      <td>0.113700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078046</td>\n",
       "      <td>0.050507</td>\n",
       "      <td>0.058628</td>\n",
       "      <td>0.037584</td>\n",
       "      <td>0.060264</td>\n",
       "      <td>0.058182</td>\n",
       "      <td>0.101859</td>\n",
       "      <td>0.023467</td>\n",
       "      <td>0.111956</td>\n",
       "      <td>0.078928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Catcher Was a Spy</th>\n",
       "      <td>0.105026</td>\n",
       "      <td>0.129720</td>\n",
       "      <td>0.134186</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.096177</td>\n",
       "      <td>0.109292</td>\n",
       "      <td>0.084539</td>\n",
       "      <td>0.099543</td>\n",
       "      <td>0.164536</td>\n",
       "      <td>0.114867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056778</td>\n",
       "      <td>0.063964</td>\n",
       "      <td>0.042044</td>\n",
       "      <td>0.030727</td>\n",
       "      <td>0.113818</td>\n",
       "      <td>0.069232</td>\n",
       "      <td>0.088568</td>\n",
       "      <td>0.046777</td>\n",
       "      <td>0.037457</td>\n",
       "      <td>0.054134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Boundaries</th>\n",
       "      <td>0.190047</td>\n",
       "      <td>0.253115</td>\n",
       "      <td>0.085488</td>\n",
       "      <td>0.096177</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.170149</td>\n",
       "      <td>0.077110</td>\n",
       "      <td>0.079705</td>\n",
       "      <td>0.111558</td>\n",
       "      <td>0.214970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100153</td>\n",
       "      <td>0.022710</td>\n",
       "      <td>0.058466</td>\n",
       "      <td>0.030532</td>\n",
       "      <td>0.057677</td>\n",
       "      <td>0.033926</td>\n",
       "      <td>0.138365</td>\n",
       "      <td>0.057276</td>\n",
       "      <td>0.118458</td>\n",
       "      <td>0.065227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8625 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "title                        Sicario: Day of the Soldado    Damsel  Distorted  \\\n",
       "title                                                                           \n",
       "Sicario: Day of the Soldado                     1.000000  0.191863   0.121058   \n",
       "Damsel                                          0.191863  1.000000   0.155643   \n",
       "Distorted                                       0.121058  0.155643   1.000000   \n",
       "The Catcher Was a Spy                           0.105026  0.129720   0.134186   \n",
       "Boundaries                                      0.190047  0.253115   0.085488   \n",
       "\n",
       "title                        The Catcher Was a Spy  Boundaries  \\\n",
       "title                                                            \n",
       "Sicario: Day of the Soldado               0.105026    0.190047   \n",
       "Damsel                                    0.129720    0.253115   \n",
       "Distorted                                 0.134186    0.085488   \n",
       "The Catcher Was a Spy                     1.000000    0.096177   \n",
       "Boundaries                                0.096177    1.000000   \n",
       "\n",
       "title                        Izzy Gets the F*ck Across Town  \\\n",
       "title                                                         \n",
       "Sicario: Day of the Soldado                        0.118741   \n",
       "Damsel                                             0.173843   \n",
       "Distorted                                          0.111801   \n",
       "The Catcher Was a Spy                              0.109292   \n",
       "Boundaries                                         0.170149   \n",
       "\n",
       "title                        Jurassic World: Fallen Kingdom  \\\n",
       "title                                                         \n",
       "Sicario: Day of the Soldado                        0.133465   \n",
       "Damsel                                             0.107899   \n",
       "Distorted                                          0.079050   \n",
       "The Catcher Was a Spy                              0.084539   \n",
       "Boundaries                                         0.077110   \n",
       "\n",
       "title                        Brothers of the Wind    Unsane    Flower  \\\n",
       "title                                                                   \n",
       "Sicario: Day of the Soldado              0.084356  0.119499  0.148502   \n",
       "Damsel                                   0.098123  0.173747  0.122491   \n",
       "Distorted                                0.142336  0.330883  0.113700   \n",
       "The Catcher Was a Spy                    0.099543  0.164536  0.114867   \n",
       "Boundaries                               0.079705  0.111558  0.214970   \n",
       "\n",
       "title                            ...       Live and Let Die  \\\n",
       "title                            ...                          \n",
       "Sicario: Day of the Soldado      ...               0.160482   \n",
       "Damsel                           ...               0.093100   \n",
       "Distorted                        ...               0.078046   \n",
       "The Catcher Was a Spy            ...               0.056778   \n",
       "Boundaries                       ...               0.100153   \n",
       "\n",
       "title                        Tintin: The Lake of Sharks  \\\n",
       "title                                                     \n",
       "Sicario: Day of the Soldado                    0.065431   \n",
       "Damsel                                         0.051277   \n",
       "Distorted                                      0.050507   \n",
       "The Catcher Was a Spy                          0.063964   \n",
       "Boundaries                                     0.022710   \n",
       "\n",
       "title                        Tales of Beatrix Potter  \\\n",
       "title                                                  \n",
       "Sicario: Day of the Soldado                 0.080594   \n",
       "Damsel                                      0.057892   \n",
       "Distorted                                   0.058628   \n",
       "The Catcher Was a Spy                       0.042044   \n",
       "Boundaries                                  0.058466   \n",
       "\n",
       "title                        Tintin: The Prisoners of the Sun  Gentle Giant  \\\n",
       "title                                                                         \n",
       "Sicario: Day of the Soldado                          0.049716      0.082526   \n",
       "Damsel                                               0.037933      0.078350   \n",
       "Distorted                                            0.037584      0.060264   \n",
       "The Catcher Was a Spy                                0.030727      0.113818   \n",
       "Boundaries                                           0.030532      0.057677   \n",
       "\n",
       "title                        Tintin: The Calculus Affair  \\\n",
       "title                                                      \n",
       "Sicario: Day of the Soldado                     0.055607   \n",
       "Damsel                                          0.039502   \n",
       "Distorted                                       0.058182   \n",
       "The Catcher Was a Spy                           0.069232   \n",
       "Boundaries                                      0.033926   \n",
       "\n",
       "title                        Visit to a Small Planet  Zoo Baby  Driftwood  \\\n",
       "title                                                                       \n",
       "Sicario: Day of the Soldado                 0.120428  0.034805   0.063027   \n",
       "Damsel                                      0.109071  0.041265   0.084943   \n",
       "Distorted                                   0.101859  0.023467   0.111956   \n",
       "The Catcher Was a Spy                       0.088568  0.046777   0.037457   \n",
       "Boundaries                                  0.138365  0.057276   0.118458   \n",
       "\n",
       "title                        Sherlock Jr.  \n",
       "title                                      \n",
       "Sicario: Day of the Soldado      0.073078  \n",
       "Damsel                           0.072520  \n",
       "Distorted                        0.078928  \n",
       "The Catcher Was a Spy            0.054134  \n",
       "Boundaries                       0.065227  \n",
       "\n",
       "[5 rows x 8625 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix_tfidfvec_truncSVD1000.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Diablo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    title\n",
       "0  Diablo"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(similarity_matrix_tfidfvec_truncSVD1000['Damsel'].sort_values(ascending=False)[1:2].index)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-237618669174>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/similarity_matrix_tfidfvec_truncSVD1000.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msimilarity_matrix_tfidfvec_truncSVD1000\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "# with open('data/similarity_matrix_tfidfvec_truncSVD1000.pkl', 'rb') as f:\n",
    "#     similarity_matrix_tfidfvec_truncSVD1000 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Killer (O Matador)'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(similarity_matrix_tfidfvec_truncSVD1000['Damsel'].sort_values(ascending=False)[1:1000]).index[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Similarity Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(similarity_matrix_tfidfvec_truncSVD1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/sim_matrix_tfidfvec_truncSVD1000.npy', sim_matrix_tfidfvec_truncSVD1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix_tfidfvec_truncSVD1000.to_csv('data/similarity_matrix_tfidfvec_truncSVD1000.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Similar Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_list = df['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Sicario: Day of the Soldado\n",
       "1                         Damsel\n",
       "2                      Distorted\n",
       "3          The Catcher Was a Spy\n",
       "4                     Boundaries\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_list[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_recommender(movie_name, movie_list, limit=3):\n",
    "    results = process.extract(movie_name, movie_list, limit=limit)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_movies():\n",
    "    movie_name = input(\"Give me a movie title and I'll give you five titles you might also like:\")\n",
    "    for title in df['title']:\n",
    "        if title == movie_name:\n",
    "            sim_movies_text = similarity_matrix_tfidfvec_truncSVD1000[movie_name]\n",
    "            print(\"Thanks! Here are my recommendations, along with review text similarity scores:\")\n",
    "            recommendations = pd.DataFrame(sim_movies_text.sort_values(ascending=False)[1:6])\n",
    "            return recommendations\n",
    "    limit = 3\n",
    "    while title != movie_name:\n",
    "        results = title_recommender(movie_name, df['title'], limit=limit)\n",
    "        print(\"Sorry, that movie title isn't in my list. Did you mean\", results, \"?\")\n",
    "        movie_name = input(\"(I need the exact title, please...)\")\n",
    "        for title in df['title']:\n",
    "            if title == movie_name:\n",
    "                sim_movies_text = similarity_matrix_tfidfvec_truncSVD1000[movie_name]\n",
    "                print(\"Thanks! Here are my recommendations, along with review text similarity scores:\")\n",
    "                recommendations = pd.DataFrame(sim_movies_text.sort_values(ascending=False)[1:6])\n",
    "                return recommendations\n",
    "            else:\n",
    "                limit += 1\n",
    "                if limit >= 10:\n",
    "                    limit = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_similar_movies():\n",
    "    movie_name = input(\"Give me a movie title and I'll give you five titles you might also like:\")\n",
    "    for title in df['title']:\n",
    "        if title == movie_name:\n",
    "            sim_movies_text = similarity_matrix_tfidfvec_truncSVD1000[movie_name]\n",
    "            print(\"Thanks! Here are my recommendations, along with review text similarity scores:\")\n",
    "            recommendations = pd.DataFrame(sim_movies_text.sort_values(ascending=False), index=df['title'])\n",
    "            return recommendations\n",
    "    limit = 3\n",
    "    while title != movie_name:\n",
    "        results = title_recommender(movie_name, df['title'], limit=limit)\n",
    "        print(\"Sorry, that movie title isn't in my list. Did you mean\", results, \"?\")\n",
    "        movie_name = input(\"(I need the exact title, please...)\")\n",
    "        for title in df['title']:\n",
    "            if title == movie_name:\n",
    "                sim_movies_text = similarity_matrix_tfidfvec_truncSVD1000[movie_name]\n",
    "                print(\"Thanks! Here are my recommendations, along with review text similarity scores:\")\n",
    "                recommendations = pd.DataFrame(sim_movies_text.sort_values(ascending=False), index=df['title'])\n",
    "                return recommendations\n",
    "            else:\n",
    "                limit += 1\n",
    "                if limit >= 10:\n",
    "                    limit = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give me a movie title and I'll give you five titles you might also like:Sicario\n",
      "Thanks! Here are my recommendations, along with review text similarity scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sicario</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sicario: Day of the Soldado</th>\n",
       "      <td>0.615682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survivor</th>\n",
       "      <td>0.411374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kate and Leopold</th>\n",
       "      <td>0.406113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Savages</th>\n",
       "      <td>0.400888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Smashed</th>\n",
       "      <td>0.392463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Sicario\n",
       "title                                \n",
       "Sicario: Day of the Soldado  0.615682\n",
       "Survivor                     0.411374\n",
       "Kate and Leopold             0.406113\n",
       "Savages                      0.400888\n",
       "Smashed                      0.392463"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar_movies()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommender System Evaluation\n",
    "#### To evaluate my recommender system, I will have my colleagues test out the system, recording what they thought about each recommendation on a 6 point scale (5 = excellent recommendation, 4= good, 3= fair, 2 = poor, 1 = unrelated, 0 = IDK, that's a movie I've never seen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def system_test(trials):\n",
    "    rate_recs = []\n",
    "    for trial in reversed(range(trials)):\n",
    "        print(\"Thank you for trying out MovieRec4Parents(tm)! You have\", trial+1, \"tries to go.\")\n",
    "        recommendations = find_similar_movies()\n",
    "        print(recommendations)\n",
    "        rate_recs.append(recommendations)\n",
    "        for rec in range(len(recommendations)):\n",
    "            print(\"On a scale of 1-5, how good is recommendation\", rec+1,\"? If you don't know the movie, enter 0.)\")\n",
    "            rating = input()\n",
    "            rate_recs.append((trial, rec+1, rating))\n",
    "    print(\"You're done! I hope you enjoyed using MovieRec4Parents(tm). Tell your friends!\")\n",
    "    return rate_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_test(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_test(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations_results = []\n",
    "rec_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_results = system_test(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations_results.append(rec_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to divide CosSimMatrix into 10 pieces so it can be uploaded to GitHub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose_sim_matrix(simmatrix=similarity_matrix_tfidfvec_truncSVD1000):\n",
    "    for a in range(575):\n",
    "        simmat0.append(simmatrix[a])\n",
    "    for b in range(575):\n",
    "        simmat1.append(simmatrix[575+b])\n",
    "    for c in range(575):\n",
    "        simmat2.append(simmatrix[575*2+c])\n",
    "    for d in range(575):\n",
    "        simmat3.append(simmatrix[575*3+d])\n",
    "    for e in range(575):\n",
    "        simmat4.append(simmatrix[575*4+e])\n",
    "    for f in range(575):\n",
    "        simmat5.append(simmatrix[575*5+f])\n",
    "    for g in range(575):\n",
    "        simmat6.append(simmatrix[575*6+g])\n",
    "    for h in range(575):\n",
    "        simmat7.append(simmatrix[575*7+h])\n",
    "    for i in range(575):\n",
    "        simmat8.append(simmatrix[575*8+i])\n",
    "    for j in range(575):\n",
    "        simmat9.append(simmatrix[575*9+j])\n",
    "    for k in range(575):\n",
    "        simmat10.append(simmatrix[575*10+k])\n",
    "    for l in range(575):\n",
    "        simmat11.append(simmatrix[575*11+l])\n",
    "    for m in range(575):\n",
    "        simmat12.append(simmatrix[575*12+m])\n",
    "    for n in range(575):\n",
    "        simmat13.append(simmatrix[575*13+n])\n",
    "    for o in range(575):\n",
    "        simmat14.append(simmatrix[575*14+o])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to Compile Cosine Similarity Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is just pseudo-code so far. Right now, to get the cosine similarity matrix you will need\n",
    "# to run myu notebooks in order. Please allow hours to do so. Or, you can contact me directly!\n",
    "def recompile_sim_matrix(simmat0=simmat0, simmat1=simmat1, simmat2=simmat2, simmat3=simmat3,\n",
    "                         simmat4=simmat4, simmat5=simmat5, simmat6=simmat6, simmat7=simmat7,\n",
    "                         simmat8=simmat8, simmat9=simmat9, simmat10=simmat10, simmat11=simmat11,\n",
    "                         simmat12=simmat12, simmat13=simmat13, simmat14=simmat14):\n",
    "    similarity_matrix_tfidfvec_truncSVD1000 = pd.DataFrame(simmat0+simmat1+simmat2+simmat3+simmat4+simmat5+simmat6+simmat7+simmat8+simmat9+simmat10+simmat11+simmat12+simmat13+simmat14)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
